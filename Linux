------------------------------------------------------------------------------------------------------------------------------------------------------------------

lspci - 

via this command, we can check the PCI devices detected via kernel

lsusb - 

via this command, we can check the usb devices attached to the system, detected by kernel

Go to /dev

To check all the hardware devices detected by kernel and the names provided to the devices. The names to the devices is being provided by 'udev' which runs in 
the background and provide the names. If the distro allows, we can update the rules to assign the names.

Go to /etc/udev 

To check all the rules via which 'udev' service assigns the names to the devices.

lsmod -

via this command, we can check all the modules loaded with kernel, modules are the drivers which are needed so that the hardware can work. When kernel detects
the hardware, it gives a name, but in order for hardware to work, it needs a driver to be present.

rmmod -

via this command, we can remove the modules, so the hardware will be there but kernel won't use the hardware as the module(driver) is being removed.
But this change is temporary, when the os reboot,the driver will be loaded again. To make this change permanent, we need to make an entry in the blacklist file.

/etc/modprobe.d

go to this directory and there will be some backlisted files, make an entry in the file for module to be removed, and it will be permanent change.

------------------------------------------------------------------------------------------------------------------------------------------------------------------

Running Linux in VM

- The names assigned by udev will be different
- Might need to install some additional tools so that Linux works well
- Need to look for shut down options to make sure the machine is actually going to sleep

------------------------------------------------------------------------------------------------------------------------------------------------------------------

Linux Boot Process -

Below are the five stages of Linux Boot Process.

1. BIOS/UEFI (Basic I/O system)

2. MBR/GPT (Master Boot Record)

3. GRUB2 (Grand Unified Bootloader)

4. Initrd / Kernel

5. systemd

Files are present in the /boot directory.

GRUB picks up the location to boot the OS. It there are more than one OS,then it will show all the option to choose from. 

/etc/default/grub   --> This file has settings defined for the grub file. If you change this file, run 'update-grub' afterwards to update /boot/grub/grub.cfg

/etc/grub.d  --> This contains files which GRUB2 will combine and compile. We can edit these files


------------------------------------------------------------------------------------------------------------------------------------------------------------------

Terminal on Linux -

Terminal is the UI which we can use to execute the commands. Under the hood, the terminal uses a Shell, it might be bash, zsh or some other shell.

ps (processes show) - run this command to see which shell is being running

uname (unix name) - this command will show the os details



------------------------------------------------------------------------------------------------------------------------------------------------------------------

Managing Processes -

When Linux OS boots, it will start a lot of processes. Each process is assigned a PID (process identifier). The process starts and finishes and that PID number 
is not assigned again to another process, so you will see the gaps in the PIDs.

ps - this command will show the processes for the current user
ps aux : this command will show all the processes for all the users across machine
top - this command will show the processes who are consuming more CPU/Memory
free - this command will show the free resources on the machine


--> We can put some interactive programs to background and bring to foreground when need to work again for e.g. if we are working on editing a file via 
    vim, then while working on vim, use command 'ctrl + z' and it will bring the vim application to background. 
    We can check all the jobs in background via 'jobs' command and can bring the application to foreground via '%1' command, for first job.
    There are 'fg' and 'bg' commands as well to put application to foreground & background.
    But this is for interactive applications and once we will close the terminal, these applications will be closed as well.
    
    If we have to run the services in the background, then we need to use 'systemctl' command which is being controlled by 'systemd'


------------------------------------------------------------------------------------------------------------------------------------------------------------------

Execution Priorities -

NOTE: In the above section we have seen that we can put processes in the background by using 'ctrl + z', but this command can keep the process running
or might stop the processes. If we want the process to keep running in background then use '&' at the end of command.

When Linux OS starts, it executes a lot of processes and on top of that the user can also runs the processes. Linux kernel treats all the processes
equally so each process gets it's turn for CPU usage. But there might be scenarios where the user would like to provide a priority to a particular 
process, so in that case the process can be started with 'nice' command. The syntax is:

nice -n <n> command

The priority can go from -20 to 19

The less the priority number, the more priority the process will get, like if the priority number is '-10' then the process will take priority from '+10'

There is a default priority of each distro, so suppose the default priority is 10, then the general users can run the process with priority 10 or more, but
only admin can run the processes with priority 9 or less

If need to amend the priority while process is running, use below command:

renice -n <n> PID -u <username>



Kill a Process:
  - run 'top' command, use 'k' and provide the PID number to kill the process
  - run the command 'kill <PID>'
  
If we run 'kill -l' , we can see all the options, but three are main:
  - number1 'SIGHUP', (Signal hangup) it is asking the process to reset or reload
  - number9 'SIGKILL' , it will kill the process
  - number15 'SIGTERM', it will ask the process to terminate gracefully
  
kill -9 <PID>


We can also kill all the threads of a particular process by name and it will kill the process for all the users: 
    $ killall chrome


------------------------------------------------------------------------------------------------------------------------------------------------------------------


nano editor - We can open more than one buffer(files) at the same time in nano and can move around to work on the files.

while doing search/replace, there is no undo option in nano, so it's better to take a backup of file before doing search/replace.

vi/vim editor - run command ': set number' so that the file will display the line numbers

y - yank (copy) the line
p - put the line

ZZ - might be used in place of ':wq'

:e! - to undo the changes and reload the file from disk


------------------------------------------------------------------------------------------------------------------------------------------------------------------

Customizing Bash -

Bash configuration files are present at two places:
    - Configuration files local for the User, these are available in home directory(.bashrc, .profile)
    - Global configuration files(these are present in /etc directory)
    
    
- We can create the variables in .bashrc file, but those will be local to shell, if need global variables, put export while declaring the variable
- We can create the alias in the .bashrc file
- We can also create the functions in the .bashrc file



------------------------------------------------------------------------------------------------------------------------------------------------------------------

Piping - 

Many newer commands support piping, but some older command doesn't, like mkdir.
If we make a file and input the directories which we have to make and pipe the file to mkdir, it will not work.

cat foldernames.txt | mkdir 

the above command will give an error.

We can use 'xargs' which support piping and will do the job.

cat foldernames.txt | xargs mkdir


------------------------------------------------------------------------------------------------------------------------------------------------------------------

Redirect - 

- If we don't need any output, we can redirect that to /dev/null. Whatever goes to /dev/null, is gone.

find / -name *.doc 2> /dev/null

- If need to write the output to screen and to the file, use the 'tee' command.


find / -name *.doc 2> /dev/null | tee list.txt

- While doing sort, it sorts on many factors and as the output of 'ls -lh' have inconsistent output format means the spaces are not consistent, so it is hard for
  sort to analyze each line. We can use 'tr' (translate) command in these situations
  
  ls -lh | tr -s " " "      " | sort -r -t "        " -k 9
  
  (to use tab in bash shell use 'ctrl +v + tab'
  
  
- the above command will provide all the columns in the output, if we just need only few columns, use the 'cut'command

  ls -lh | tr -s " " "      " | sort -r -t "        " -k 9 | cut -d "       " -f 5,9
  
  
- Use 'egrep' if need to use regular expression with grep


------------------------------------------------------------------------------------------------------------------------------------------------------------------

Working with checksums -

- To check which checksum utility are present use,
    ls /usr/bin/*sum
    
- Checksums are being used to ensure that the file is not modified during transmission

- 'md5sum' is not considered much secure

- 'shasum' is considered to be more secure, it has different versions like 'sha128sum' 'sha256sum' 'sha512sum'

- The bigger the number, the more digits it will produce, the more diffucult to break it

- But the bigger number will take more time to create the checksum for bigger files, so need to make a balance



------------------------------------------------------------------------------------------------------------------------------------------------------------------

Locating Files/Binaries:

- We can use below commands:

        - type: it will tell whether the command is binary or function
           'type vim'
        - locate: it maintains a database, so it takes a lot of harddisk space and database needs to be updated so that this can work fine
           ' locate vim'
        - whereis: it searches in the $PATH and give all the instances, but won't tell which one will be executed
           ' whereis vim'
        - which: it searches in the $PATH and will give the first hit, which will eventually be executed by Bash
           ' which vim'
           
           
     

- Find Command (check that in this command we use '-name' instead of '--name':

    - This command is useful to search the files with name/size/etc...
    - 'find / -name *.pdf'
    - 'find / -size +20M'



- 'Grep -r' command to find the files:
    - We can use the 'grep -r' command to find the files based on the content
    - Use 'grep -r "Test' /
    - In this command, we first provide the word which needs to be searched and then the path, this is opposite to find command



------------------------------------------------------------------------------------------------------------------------------------------------------------------

Hard and Soft Link -

- Hard link points to a specific raw data, so it can't be created for a directory.
- Hard Link can only be created within the same volume/same harddisk
- After file permissions there is a number, that number tells how many hardlinks are present for a file
- To create the hardlink, 'ln text.txt text-link.txt'

- Soft link points to a path, so soft link can be created for a directory
- To create the softlink for a file, 'ln -s text.txt text-link.txt'
- To create a softlink for a directory, 'ln -s /home/Desktop/Data/Linux/Work /home/medha'



------------------------------------------------------------------------------------------------------------------------------------------------------------------

File Ownership -

- Whenever we create a new file/directory, it picks up the owner/group information of the user who is creating the file/directory
- If we run the 'id' command, we can see the owner/group id, this is from where system picks up the information and assign to the new file/directory
- The owner is important for a file/directory, as if we remove all the permissions from file/directory, then also the owner can access the file/directory
- To change the owner of a file/directory,
    - chown <new-owner> file
- To change the owner/group of a file/directory,
    - chown <new-owner> : <new-group> file
- To change the group of a file/directory,
    - chgrp <new-group> file


- If we change the owner of a directory, the files created inside the directory doesn't inherit the owner, but files inherit the permissions of a directory
- If we want that the new files created inside a directory inherit the group of the directory, we need to use the sticky bit
    - chmod g+s <directory>
- We can verify whether a directory has sticky bit set by looking into the directory permissions,
    - drwxrwsrwx 1 root root 4 Dec 10:49 new-file.txt
    - We can see that in the group permissions, there is a 's' , which indicates that sticky bit applied on the group
    - sticky bit only set the group inside the directory for the new files created, not on the existing files
    - if we copy a file to the directory, where sticky bit is applied, it will set the group of the file to the same as directory group, as copy creates a new file
    - if we move a file to the directory, where sticky bit is applied, it will not a file to the directory, where sticky bit is applied, as move doesn't creates a new file
  
- We can apply the sticky bit to User or Group on the directory permissions, and the new files created will take the same user/group as of directory.   



POSIX Based file permissions - 


- When we create a new directory, it gets some default permissions, but from where it gets the permission,
    - it can get the permissions from /etc/profile
    - or the permissions might be in .bashrc
    - but eventually all the permissions are maintained by 'umask' i.e. umask provides the default permissions
    



ACL (Access Control List) or FACL (File Access Control List) Based file permissions - 


fstab - filesystem table


- The challange with POSIX based file permissions are, that they support one owner, one group and others.
- ACL allows a list of users/groups and we can define what permission each user/group will have, this is not possible with POSIX based permissions.
- Now as each computer is connected to network, we would like to have more than one user or group to have access to a file/directory.
- When we assign the FACL based permissions, the POSIX permission will not go away
- On some distro, the ACL might be a active by default or we might need to activate the ACL
- When we mount a volume, there we need to define whether we want ACL to be active
- We can check this at /etc/fstab
- We can check the defaults of a volume by:
    $ tune2fs -l /dev/sda5


- Two main commands to work with ACLs:
    - getfacl
    - setfacl
    
    
    
- To check whether the ACLs are applied to a Directory/File
    - there will be a '+' sign at the end of permissions, like
        drwxrwxrwx+ 1 .......
- To set the permissions:
    $ setfacl -m u:<username>:rw <filename>
    $ setfacl -m g:<groupname>:rw <filename>

- To check the FACL permissions:
    $ getfactl <filename>

- But when we set the ACL by this way on directory, the files created inside the directory will not inherit these permissions
    $ setfacl -m g:<groupname>:r <directory>
    
- So we need to set the FACL by some extra option so that the permissions will be inherited by files created inside the directory
    $ setfacl -m d:g:<groupname>:r <directory>
    
- The 'd' option is the default permissions of a directory which the new files will inherit from directory

- when we set the FACL, it will create a mask (max permissions) as well, mask is a set of permissions i.e.the maximum permission a user/group can have.



------------------------------------------------------------------------------------------------------------------------------------------------------------------

Shared Libraries -

- Shared Libraries are common piece of functionality present which can be shared among many processes.If any process needs a particular functionality and 
the functionality is present in the library, then the program can include the shared library instead of writing the functionality again.

- Libraries are present at:
    - /lib
    - /lib32
    - /lib64
    - /usr/lib
    - /usr/lib32
    - /usr/lib64
    - some other places as well



- To check all the library information, run the below command (ldconfig = library deamon configuration):
    $ ldconfig -v


- ldconfig picks up the configuration from below files:
    $ /etc/ld.so.conf
    $ /etc/ld.so.conf.d
    
    
- To check what libraries a particular process is using, use the below command (ldd = library deamon dependency):

    $ ldd /bin/bash
    $ ldd /bin/vim
    
    
- If we want to create our own libraries, the safe place is to create in the home folder under '/home/user/.local/lib'
- After creating a lib directory in the home directory, need to update 'ldconfig' so that it can pick up the local libraries as well.

    $ sudo ldconfig -n /home/user/.local/lib
    
- We can also update the 'ldconfig' configuration so that liconfig can update the local libraries:

    $ sudo cp x86_64_linux-gnu.conf ./custom.conf

    $ sudoedit custom.conf  (add /home/user/.local/lib in this custom.conf file)




------------------------------------------------------------------------------------------------------------------------------------------------------------------

Managing Software Packages - 


(Debian Based Distro)

- There are three package managers which can be used on Debian Based Distros for software Management:

1. dpkg -> this was the first one, but it doesn't track dependencies while installing the packages

2. apt-get -> this comes second and it install the dependencies as well while installing the packages and maitaines a database to track the dependencies.
              But the challanges is that when more packages are being installed, it becomes challenging for apt-get to manage the database.

3. apt -> this is the latest one and similar to apt-get but much efficient to track the database to track dependencies


- Each Distro maintains a list of repositories to install the packages
- This repo is being placed at: /etc/apt/sources.list & /etc/apt/sources.list.d

- When we run the command: 'sudo apt install mc', it pulls the packages from the local repo maintains by the distro

- We can also install the package from internet and store on local disk and then provide the name of local file while installing the package:
    $ sudo apt install <local-file-download-path>
    
- Some packages provides the instruction on how we can add the package to '/etc/apt/sources.list.d' and then update.
    - we can check this for 'webmin'


- There is a service called 'automatic-update' which runs in the background once/day to update the packages in '/etc/apt/sources.list'. But this service
    runs for full install OS.

- Sequence for installing packages:
    - sudo apt update (this will just update the database for apt)
    - sudo apt upgrade (this will update the actual packages)
    - sudo apt dist-upgrade (this will update the kernel version)
    - sudo apt remove (this will remove the packages)
    - sudo apt autoremove (this will remove any dependency which is not being used by any package)
    
    
    


(Red Hat Distro)


- There are three package managers:

1. rpm - redhat package manager , not great for installing dependencies, it install the packages offline i.e. from local disk
2. yum - yellowdog update manager, install dependencies as well, for larger packages it might miss a dependency
3. dnf - (latest) it handles the dependency database management much better than yum

- rpm install softwares offline i.e. doesn't go to internet and take package from local disk

- yum, dnf install packages via internet

- yum install packages from redhat official repo

- There is a repo which each distro maintains to install the packages: 
    $ /etc/yum/repos.d/

- If a software not available in the repo, we can install some software from internet locally and then can install

    $ sudo rpm install <local-pkg> or 
    $ sudo yum install <local-pkg> or
    $ sudo dnf install <local-pkg>

- Some software packages provides the info to update the repo and then install the software like 'webwin'

-  We can install dnf-automatic package, which will run as per the defined frequency and updates the packages, but RHEL will not allow this

- To update the software packages:
    $ sudo yum update (to update both s/w and kernel)

- To remove a software package:
    $ sudo yum remove

- To remove from dnf:
    $ sudo dnf autoremove

- When we remove the packages via 'sudo yum remove <pkg>' command, it removes the package but keeps a cache copy, run below command to remove the cache copy:
    $ sudo yum erase <pkg> 



------------------------------------------------------------------------------------------------------------------------------------------------------------------

Supporting Services:


- When Kernel starts, it triggers the init system which is responsible to run all the further processes
- init system is a separate application than kernel
- There are three init systems:

1. system-V init: (system 5 initialization), first init system created for Unix, (not good to track the removable hardware like usb), collection of scripts
2. upstart - came after sysvinit, very similar to sysvinit and collection of scripts, it was originally developed for the Ubuntu distro v6 in 2006, 
            completely compatible with sysvinit and track the removable hardware, but it was not very powerful and executed the processes sequentially
3. systemd - developed in 2010 by Red hat, more powerful than upstart, can run processes in parallel, this is the default init system now a days and 
            used by the major distros
         
- To verify which init is being running by the kernel, check all the processes, as init is the first process which is being triggered by the kernel, so check
the process with process id 1 and by that we will get to know which init kernel is running. If it is pointing to systemd then we know that kernel is using 
systemd, if it is using just init, then it might be sysvinit or upstart, to check this further, go to the man page for init, and there we can check 
whether it is for sysvinit or upstart.






Introduction to SysVinit:

- when SysVinit starts, it is a binary which runs and it picks up the config files, the config files are placed at below paths:
    $ /etc/rc.d   rc.local rc.sysinit
    $ /etc/rc.local, rc.sysinit

- check the script in rc.sysinit config file, this is being loaded by SysVinit

- rc.local - for user changes
- rc.sysinit - provided by distro, it there are any changes, this file will be overwritten

- init system tracks the state of machine via run levels

- /etc/inittab (init table) - to check all the run level of machine, this contains the default run level to which machine will boot

- run levels are -> from 0 to 6

- config files for run level 0 to 6 are present at:
    - /etc/rc.d/rc0.d...rc6.d

- first rc.sysinit runs and then run level confg (for e.g. rc0.d) files will be execued

- to check the run level:
        $ runlevel
        $ who -r
        
- We can change the run level of a machine, if we change the run level to reboot then the system will reboot, but some run levels doesn't need reboot,       
    - 'sudo init 3' or 'sudo telinit 3' -> this will change the run level to 3 without rebooting
    - 'sudo init 5' or 'sudo telinit 5' -> this will change the run level to 5 without rebooting




Managing services with SysVinit:



We don't need to edit the config files, we can manage the services via two commands, 'chkconfig' & 'service'

$ sudo chkconfig httpd on -> this will set the service to run on boot

$ sudo service httpd status/start/stop/restart -> to control the status of service

$ sudo chkconfig --list (to see on what run levels the service will run)

$ sudo chkconfig --level 35 httpd on -> this will set the service to run on boot on run levels 3,5

$ /etc/rc.d/init.d - some run levels run from init.d






Introduction to systemd:


service == deamon, program that does in the background

can run scripts in parallel, faster boot time, not backward compatible,

/lib/systemd/system - systemd configuration, these are called units, part of distro
/etc/systemd/system - user provided custom changes



/lib/systemd/system - has the files for the services, ssh.service
/lib/systemd/system - it has the targets which are being executed by systemd


systemd does not have runlevels, so it maps the runlevels to the targets, for backward compatability


systemctl get-default -> this will provide the default target in which the system boots

sudo systemctl set-default multi-user.target -> this will change the default-target to boot

sudo systemctl isolate multi-user.target -> it will change the default target without rebooting

sudo systemctl isolate graphical.target -> to move gui without rebooting



Managing services with systemd:


systemd works on the target, it has the default target like multi-user.target, and it boots the system from target. We can check what targets/services 
will get loaded in this target.

sudo systemctl enable ssh -> to tell systemd to run ssh service at boot time, but will not start the service

sudo systemctl enagle --now ssh -> it will run the service at boot time and now as well

sudo systemctl status apache2

sudo systemctl enable --now apache2

sudo systemctl start apache2

If need to configure our own application as a service, create a service file in /etc/systemd/system and manage it with systemctl.











